{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Tense Table Constructor\n",
    "This notebook demonstrates how English verb tables for regular/irregular verbs can be automatically-generated using a few rules and regex. The notebook makes use of sre_yield to generate all strings matching a given expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\Christian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports.\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "import re\n",
    "import sre_yield\n",
    "from nltk.corpus import cmudict\n",
    "import nltk\n",
    "nltk.download('cmudict')\n",
    "import src.verb_inflect as verb_inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables.\n",
    "d = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions.\n",
    "def nsyl(word):\n",
    "    return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/regular_verbs.html', 'w') as f:\n",
    "    f.write(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load regular verb data.\n",
    "try:\n",
    "    webpage = requests.get('https://www.englishclub.com/vocabulary/regular-verbs-list.htm').text\n",
    "    \n",
    "except Exception:\n",
    "    with open('res/regular_verbs.html', 'r') as f:\n",
    "        webpage = f.read()\n",
    "        \n",
    "soup = bs4.BeautifulSoup(webpage, 'html.parser')\n",
    "regulars = []\n",
    "for body in soup.find_all('tbody'):\n",
    "    for tr in body.find_all('tr'):\n",
    "        for td in tr.find_all('td'):\n",
    "            words = str(td)\n",
    "            regulars += words.replace('<td>', ' ').replace('<br>', ' ').replace('</br>', ' ').replace('</td>', ' ').replace('(AmE)', ' ').replace('(BrE)', ' ').split()\n",
    "\n",
    "verb_stems_regular = list(filter(lambda x: len(x) > 0, regulars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process regular verb data.\n",
    "df_regular = pd.DataFrame(index=[i for i in range(len(verb_stems_regular))], columns=['source'])\n",
    "filler = [str(0) for i in range(len(df_regular.values))]\n",
    "df_regular['lemma'] = verb_stems_regular\n",
    "df_regular['wethey_past'] = filler\n",
    "df_regular['pastpart'] = filler\n",
    "df_regular['i_pres'] = filler\n",
    "df_regular['wethey_pres'] = filler\n",
    "df_regular['you_pres'] = filler\n",
    "df_regular['hsi_pres'] = filler\n",
    "df_regular['prespart'] = filler\n",
    "df_regular['i_past'] = filler\n",
    "df_regular['you_past'] = filler\n",
    "df_regular['hsi_past'] = filler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process irregular verb data.\n",
    "df_irregular = pd.read_csv('res/verbs_irregular.csv').drop(['german'], axis=1)\n",
    "filler = [str(0) for i in range(len(df_irregular.values))]\n",
    "df_irregular['i_pres'] = filler\n",
    "df_irregular['wethey_pres'] = filler\n",
    "df_irregular['you_pres'] = filler\n",
    "df_irregular['hsi_pres'] = filler\n",
    "df_irregular['prespart'] = filler\n",
    "df_irregular['i_past'] = filler\n",
    "df_irregular['you_past'] = filler\n",
    "df_irregular['hsi_past'] = filler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish endings for different regular inflection paradigms.\n",
    "es_endings = ['ch', 'sh', 's', 'x', 'z', 'ss']\n",
    "cy_endings = []\n",
    "for each in sre_yield.AllStrings(r'[b-df-hj-np-tv-z]y'):\n",
    "    cy_endings.append(each)\n",
    "\n",
    "vc_endings = []\n",
    "for each in sre_yield.AllStrings(r'[b-df-hj-np-tv-xz][aeiou][b-df-hj-np-tv-xz]'):\n",
    "    vc_endings.append(each)\n",
    "    \n",
    "very_irregular = ['may', 'be', 'do', 'have'] # TODO: account for 'lie' forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irregular verb inflections.\n",
    "for i in range(len(df_irregular)):\n",
    "        \n",
    "\tif 'kein Participle' in str(df_irregular.at[i, 'pastpart']):\n",
    "\t\tdf_irregular.at[i, 'pastpart'] = '[None]'\n",
    "\telif len(df_irregular.at[i, 'pastpart'].split(', ')) >= 2:\n",
    "\t\ttpl = df_irregular.at[i, 'pastpart'].split(', ')\n",
    "\t\tdf_irregular.at[i, 'pastpart'] = tpl[0]\n",
    "\telif len(df_irregular.at[i, 'pastpart'].split(', ')) == 1:\n",
    "\t\tdf_irregular.at[i, 'pastpart'] = df_irregular.at[i, 'pastpart']\n",
    "\n",
    "\tdf_irregular.at[i, 'i_pres'] = df_irregular.at[i, 'lemma']\n",
    "\tdf_irregular.at[i, 'wethey_pres'] = df_irregular.at[i, 'lemma']\n",
    "\tdf_irregular.at[i, 'you_pres'] = df_irregular.at[i, 'lemma']\n",
    "\t\n",
    "\tif any(df_irregular.at[i, 'lemma'].endswith(ending) for ending in es_endings):\n",
    "\t\tdf_irregular.at[i, 'hsi_pres'] = df_irregular.at[i, 'lemma'] + 'es'\n",
    "\n",
    "\telif any(df_irregular.at[i, 'lemma'].endswith(ending) for ending in cy_endings):\n",
    "\t\tdf_irregular.at[i, 'hsi_pres'] = df_irregular.at[i, 'lemma'][:-1] + 'ies'\n",
    "\n",
    "\telse:\n",
    "\t\tdf_irregular.at[i, 'hsi_pres'] = df_irregular.at[i, 'lemma'] + 's'\n",
    "\n",
    "\tif df_irregular.at[i, 'lemma'].endswith('ie'):\n",
    "\t\tdf_irregular.at[i, 'prespart'] = df_irregular.at[i, 'lemma'][:-2] + 'ying'\n",
    "\n",
    "\telif df_irregular.at[i, 'lemma'].endswith('e'):\n",
    "\t\tdf_irregular.at[i, 'prespart'] = df_irregular.at[i, 'lemma'][:-1] + 'ing'\n",
    "\n",
    "\telse:\n",
    "\t\ttry:\n",
    "\t\t\tif ((nsyl(df_irregular.at[i, 'lemma']) == 2) and (df_irregular.at[i, 'lemma'][-3:] in vc_endings) \n",
    "                                            and (df_irregular.at[i, 'lemma'][-1:] not in ['w', 'x'])\n",
    "                                            and [i for i in d[df_irregular.at[i, 'lemma']][0] if len(str(i)) == 3][0][2] == '1'):\n",
    "\t\t\t\tdf_irregular.at[i, 'prespart'] = df_irregular.at[i, 'lemma'] + 'ing'                        \n",
    "\t\t\telif (nsyl(df_irregular.at[i, 'lemma']) == 1 or 2) and (df_irregular.at[i, 'lemma'][-3:] in vc_endings) and (df_irregular.at[i, 'lemma'][-1:] not in ['w', 'x']):\n",
    "\t\t\t\tdf_irregular.at[i, 'prespart'] = df_irregular.at[i, 'lemma'] + df_irregular.at[i, 'lemma'][-1:] + 'ing'\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tdf_irregular.at[i, 'prespart'] = df_irregular.at[i, 'lemma'] + 'ing'\n",
    "\n",
    "\t\texcept KeyError:\n",
    "\t\t\tdf_irregular.at[i, 'prespart'] = df_irregular.at[i, 'lemma'] + 'ing' \n",
    "            \n",
    "\tif len(df_irregular.at[i, 'wethey_past'].split(', ')) == 3:\n",
    "\t\ttpl = df_irregular.at[i, 'wethey_past'].split(', ')\n",
    "\t\tdf_irregular.at[i, 'wethey_past'] = tpl[2]\n",
    "\t\tdf_irregular.at[i, 'hsi_past'] = tpl[0]\n",
    "            \n",
    "\telif len(df_irregular.at[i, 'wethey_past'].split(', ')) == 2:\n",
    "\t\ttpl = df_irregular.at[i, 'wethey_past'].split(', ')\n",
    "\t\tdf_irregular.at[i, 'wethey_past'] = tpl[1]\n",
    "\t\tdf_irregular.at[i, 'hsi_past'] = tpl[0]\n",
    "\n",
    "\telif len(df_irregular.at[i, 'wethey_past'].split(', ')) == 1:\n",
    "\t\tdf_irregular.at[i, 'hsi_past'] = df_irregular.at[i, 'wethey_past']\n",
    "\t\t\n",
    "\tdf_irregular.at[i, 'i_past'] = df_irregular.at[i, 'wethey_past']\n",
    "\tdf_irregular.at[i, 'you_past'] = df_irregular.at[i, 'wethey_past']\n",
    "    \n",
    "\tif df_irregular.at[i, 'lemma'] in very_irregular:\n",
    "\t\tif df_irregular.at[i, 'lemma'] == 'be':\n",
    "\t\t\tdf_irregular.at[i, 'i_past'] = 'was'\n",
    "\t\t\tdf_irregular.at[i, 'i_pres'] = 'am'\n",
    "\t\t\tdf_irregular.at[i, 'wethey_pres'] = 'are'\n",
    "\t\t\tdf_irregular.at[i, 'you_pres'] = 'are'\n",
    "\t\t\tdf_irregular.at[i, 'hsi_pres'] = 'is'\n",
    "\t\t\tdf_irregular.at[i, 'prespart'] = 'being'\n",
    "            \n",
    "\t\tif df_irregular.at[i, 'lemma'] == 'do':\n",
    "\t\t\tdf_irregular.at[i, 'hsi_pres'] = 'does'\n",
    "\t\tif df_irregular.at[i, 'lemma'] == 'have':\n",
    "\t\t\tdf_irregular.at[i, 'hsi_pres'] = 'has'\n",
    "\t\tif df_irregular.at[i, 'lemma'] ==  'may':\n",
    "\t\t\tdf_irregular.at[i, 'hsi_pres'] = 'may'\n",
    "\t\t\tdf_irregular.at[i, 'prespart'] = '[None]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular verb inflections.\n",
    "for i in range(len(df_regular)):\n",
    "\tdf_regular.at[i, 'lemma'] = verb_inflect.verb_infinitive(df_regular.at[i, 'lemma'])\n",
    "\n",
    "\tif not re.match(r'[a-z]', df_regular.at[i, 'lemma']):\n",
    "\t\tdf_regular.at[i, 'lemma'] = '&&&'\n",
    "\t\n",
    "\tif df_regular.at[i, 'lemma'].endswith('ie'):\n",
    "\t\tdf_regular.at[i, 'wethey_past'] = df_regular.at[i, 'lemma'] + 'd'\n",
    "\n",
    "\telif df_regular.at[i, 'lemma'].endswith('e'):\n",
    "\t\tdf_regular.at[i, 'wethey_past'] = df_regular.at[i, 'lemma'] + 'd'\n",
    "\n",
    "\telif any(df_regular.at[i, 'lemma'].endswith(ending) for ending in cy_endings):\n",
    "\t\tdf_regular.at[i, 'hsi_pres'] = df_regular.at[i, 'lemma'][:-1] + 'ied'\n",
    "\t\tdf_regular.at[i, 'wethey_past'] = df_regular.at[i, 'lemma'][:-1] + 'ied'\n",
    "\n",
    "\telse:\n",
    "\t\ttry:\n",
    "\t\t\tif ((nsyl(df_regular.at[i, 'lemma']) == 2) and (df_regular.at[i, 'lemma'][-3:] in vc_endings) \n",
    "                                            and (df_regular.at[i, 'lemma'][-1:] not in ['w', 'x'])\n",
    "                                            and [i for i in d[df_regular.at[i, 'lemma']][0] if len(str(i)) == 3][0][2] == '1'):\n",
    "\t\t\t\tdf_regular.at[i, 'wethey_past'] = df_regular.at[i, 'lemma'] + 'ed'\n",
    "\t\t\telif (nsyl(df_regular.at[i, 'lemma']) == (1 or 2)) and (df_regular.at[i, 'lemma'][-3:] in vc_endings) and (df_regular.at[i, 'lemma'][-1:] not in ['w', 'x']):\n",
    "\t\t\t\tdf_regular.at[i, 'wethey_past'] = df_regular.at[i, 'lemma'] + df_regular.at[i, 'lemma'][-1:] + 'ed'\n",
    "                \n",
    "\t\t\telse:\n",
    "\t\t\t\tdf_regular.at[i, 'wethey_past'] = df_regular.at[i, 'lemma'] + 'ed'\n",
    "\t\t\t\tdf_regular.at[i, 'hsi_pres'] = df_regular.at[i, 'lemma'] + 'ed'\n",
    "\n",
    "\t\texcept KeyError:\n",
    "\t\t\tdf_regular.at[i, 'wethey_past'] = df_regular.at[i, 'lemma'] + 'ed' \n",
    "\n",
    "\tdf_regular.at[i, 'pastpart'] = df_regular.at[i, 'wethey_past']\n",
    "\tdf_regular.at[i, 'i_pres'] = df_regular.at[i, 'lemma']\n",
    "\tdf_regular.at[i, 'wethey_pres'] = df_regular.at[i, 'lemma']\n",
    "\tdf_regular.at[i, 'you_pres'] = df_regular.at[i, 'lemma']\n",
    "\t\n",
    "\tif any(df_regular.at[i, 'lemma'].endswith(ending) for ending in es_endings):\n",
    "\t\tdf_regular.at[i, 'hsi_pres'] = df_regular.at[i, 'lemma'] + 'es'\n",
    "\n",
    "\telif any(df_regular.at[i, 'lemma'].endswith(ending) for ending in cy_endings):\n",
    "\t\tdf_regular.at[i, 'hsi_pres'] = df_regular.at[i, 'lemma'][:-1] + 'ies'\n",
    "\n",
    "\telse:\n",
    "\t\tdf_regular.at[i, 'hsi_pres'] = df_regular.at[i, 'lemma'] + 's'\n",
    "\n",
    "\tif df_regular.at[i, 'lemma'].endswith('ie'):\n",
    "\t\tdf_regular.at[i, 'prespart'] = df_regular.at[i, 'lemma'][:-2] + 'ying'\n",
    "\n",
    "\telif df_regular.at[i, 'lemma'].endswith('ee'):\n",
    "\t\tdf_regular.at[i, 'prespart'] = df_regular.at[i, 'lemma'] + 'ing'\n",
    "\n",
    "\telif df_regular.at[i, 'lemma'].endswith('e'):\n",
    "\t\tdf_regular.at[i, 'prespart'] = df_regular.at[i, 'lemma'][:-1] + 'ing'\n",
    "\n",
    "\telse:\n",
    "\t\ttry:\n",
    "\t\t\tif ((nsyl(df_regular.at[i, 'lemma']) == 2) and (df_regular.at[i, 'lemma'][-3:] in vc_endings) \n",
    "                                            and (df_regular.at[i, 'lemma'][-1:] not in ['w', 'x'])\n",
    "                                            and [i for i in d[df_regular.at[i, 'lemma']][0] if len(str(i)) == 3][0][2] == '1'):\n",
    "\t\t\t\tdf_regular.at[i, 'prespart'] = df_regular.at[i, 'lemma'] + 'ing'\n",
    "\t\t\telif (nsyl(df_regular.at[i, 'lemma']) == (1 or 2)) and (df_regular.at[i, 'lemma'][-3:] in vc_endings) and (df_regular.at[i, 'lemma'][-1:] not in ['w', 'x']):\n",
    "\t\t\t\tdf_regular.at[i, 'prespart'] = df_regular.at[i, 'lemma'] + df_regular.at[i, 'lemma'][-1:] + 'ing'\n",
    "                \n",
    "\t\t\telse:\n",
    "\t\t\t\tdf_regular.at[i, 'prespart'] = df_regular.at[i, 'lemma'] + 'ing'\n",
    "\n",
    "\t\texcept KeyError:\n",
    "\t\t\tdf_regular.at[i, 'prespart'] = df_regular.at[i, 'lemma'] + 'ing' \n",
    "\n",
    "\n",
    "\tdf_regular.at[i, 'i_past'] = df_regular.at[i, 'wethey_past']\n",
    "\tdf_regular.at[i, 'you_past'] = df_regular.at[i, 'wethey_past']\n",
    "\tdf_regular.at[i, 'hsi_past'] = df_regular.at[i, 'wethey_past']\n",
    "\n",
    "\tif df_regular.at[i, 'lemma'] == '&&&':\n",
    "\t\tdf_regular = df_regular.drop(index=i)\n",
    "\n",
    "df_regular = df_regular.drop('source', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine regular and irregular verb lists.\n",
    "df_combined = pd.concat([df_irregular, df_regular], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>wethey_past</th>\n",
       "      <th>pastpart</th>\n",
       "      <th>i_pres</th>\n",
       "      <th>wethey_pres</th>\n",
       "      <th>you_pres</th>\n",
       "      <th>hsi_pres</th>\n",
       "      <th>prespart</th>\n",
       "      <th>i_past</th>\n",
       "      <th>you_past</th>\n",
       "      <th>hsi_past</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alight</td>\n",
       "      <td>alit</td>\n",
       "      <td>alighted</td>\n",
       "      <td>alight</td>\n",
       "      <td>alight</td>\n",
       "      <td>alight</td>\n",
       "      <td>alights</td>\n",
       "      <td>alighting</td>\n",
       "      <td>alit</td>\n",
       "      <td>alit</td>\n",
       "      <td>alighted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arise</td>\n",
       "      <td>arose</td>\n",
       "      <td>arisen</td>\n",
       "      <td>arise</td>\n",
       "      <td>arise</td>\n",
       "      <td>arise</td>\n",
       "      <td>arises</td>\n",
       "      <td>arising</td>\n",
       "      <td>arose</td>\n",
       "      <td>arose</td>\n",
       "      <td>arose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awake</td>\n",
       "      <td>awaked</td>\n",
       "      <td>awoken</td>\n",
       "      <td>awake</td>\n",
       "      <td>awake</td>\n",
       "      <td>awake</td>\n",
       "      <td>awakes</td>\n",
       "      <td>awaking</td>\n",
       "      <td>awaked</td>\n",
       "      <td>awaked</td>\n",
       "      <td>awoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>be</td>\n",
       "      <td>were</td>\n",
       "      <td>been</td>\n",
       "      <td>am</td>\n",
       "      <td>are</td>\n",
       "      <td>are</td>\n",
       "      <td>is</td>\n",
       "      <td>being</td>\n",
       "      <td>was</td>\n",
       "      <td>were</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bear</td>\n",
       "      <td>bore</td>\n",
       "      <td>borne</td>\n",
       "      <td>bear</td>\n",
       "      <td>bear</td>\n",
       "      <td>bear</td>\n",
       "      <td>bears</td>\n",
       "      <td>bearing</td>\n",
       "      <td>bore</td>\n",
       "      <td>bore</td>\n",
       "      <td>bore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>visit</td>\n",
       "      <td>visited</td>\n",
       "      <td>visited</td>\n",
       "      <td>visit</td>\n",
       "      <td>visit</td>\n",
       "      <td>visit</td>\n",
       "      <td>visits</td>\n",
       "      <td>visiting</td>\n",
       "      <td>visited</td>\n",
       "      <td>visited</td>\n",
       "      <td>visited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>yawn</td>\n",
       "      <td>yawned</td>\n",
       "      <td>yawned</td>\n",
       "      <td>yawn</td>\n",
       "      <td>yawn</td>\n",
       "      <td>yawn</td>\n",
       "      <td>yawns</td>\n",
       "      <td>yawning</td>\n",
       "      <td>yawned</td>\n",
       "      <td>yawned</td>\n",
       "      <td>yawned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>yell</td>\n",
       "      <td>yelled</td>\n",
       "      <td>yelled</td>\n",
       "      <td>yell</td>\n",
       "      <td>yell</td>\n",
       "      <td>yell</td>\n",
       "      <td>yells</td>\n",
       "      <td>yelling</td>\n",
       "      <td>yelled</td>\n",
       "      <td>yelled</td>\n",
       "      <td>yelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>zip</td>\n",
       "      <td>zipped</td>\n",
       "      <td>zipped</td>\n",
       "      <td>zip</td>\n",
       "      <td>zip</td>\n",
       "      <td>zip</td>\n",
       "      <td>zips</td>\n",
       "      <td>zipping</td>\n",
       "      <td>zipped</td>\n",
       "      <td>zipped</td>\n",
       "      <td>zipped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>zoom</td>\n",
       "      <td>zoomed</td>\n",
       "      <td>zoomed</td>\n",
       "      <td>zoom</td>\n",
       "      <td>zoom</td>\n",
       "      <td>zoom</td>\n",
       "      <td>zooms</td>\n",
       "      <td>zooming</td>\n",
       "      <td>zoomed</td>\n",
       "      <td>zoomed</td>\n",
       "      <td>zoomed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lemma wethey_past  pastpart  i_pres wethey_pres you_pres hsi_pres  \\\n",
       "0   alight        alit  alighted  alight      alight   alight  alights   \n",
       "1    arise       arose    arisen   arise       arise    arise   arises   \n",
       "2    awake      awaked    awoken   awake       awake    awake   awakes   \n",
       "3       be        were      been      am         are      are       is   \n",
       "4     bear        bore     borne    bear        bear     bear    bears   \n",
       "..     ...         ...       ...     ...         ...      ...      ...   \n",
       "88   visit     visited   visited   visit       visit    visit   visits   \n",
       "94    yawn      yawned    yawned    yawn        yawn     yawn    yawns   \n",
       "95    yell      yelled    yelled    yell        yell     yell    yells   \n",
       "96     zip      zipped    zipped     zip         zip      zip     zips   \n",
       "97    zoom      zoomed    zoomed    zoom        zoom     zoom    zooms   \n",
       "\n",
       "     prespart   i_past you_past  hsi_past  \n",
       "0   alighting     alit     alit  alighted  \n",
       "1     arising    arose    arose     arose  \n",
       "2     awaking   awaked   awaked     awoke  \n",
       "3       being      was     were       was  \n",
       "4     bearing     bore     bore      bore  \n",
       "..        ...      ...      ...       ...  \n",
       "88   visiting  visited  visited   visited  \n",
       "94    yawning   yawned   yawned    yawned  \n",
       "95    yelling   yelled   yelled    yelled  \n",
       "96    zipping   zipped   zipped    zipped  \n",
       "97    zooming   zoomed   zoomed    zoomed  \n",
       "\n",
       "[197 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
